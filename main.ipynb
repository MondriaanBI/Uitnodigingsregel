{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a67d009d-0eb0-4c5f-a26b-8abfe5a1ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a11a2340-3692-4cfd-a6f7-bb0c247dc189",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import .py scripts from subdirectories \n",
    "\n",
    "# Import config file that contains settings that can be adjusted\n",
    "from module.config import *\n",
    "# Import script with basic data cleaning: drop duplicate rows and change NA values of numerical columns to the column mean\n",
    "from module.dataset import *\n",
    "# Import script that contains 3 models that train on the train dataset. Tuning is done with GridsearchCV. The models are Random Forest (RF),\n",
    "# Lasso Regression (lasso) and Support Vector Machines (SVM)\n",
    "from module.modeling.train import *\n",
    "# Import python script that contains feature engineering. The first function checks a dataset for categorical columns and changes them\n",
    "# using dummy variables. The second function standardizes the data using a minmax scaler. This is needed for the lasso and SVM models\n",
    "from module.features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c95dc98-ef92-45b9-8002-dae234e02390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-uploaded synthetic datasets found and loaded\n"
     ]
    }
   ],
   "source": [
    "# Check if train.csv and pred.csv exist in user_data folder, otherwise load synthetic datasests\n",
    "# When user data is loaded and an error occurs here, please check if the sep = '\\t' needs to be changed to another seperator like ',' or '.'\n",
    "# This should be the same as the seperator used in your .csv file\n",
    "if os.path.exists(user_data_dir_train) and os.path.exists(user_data_dir_pred):\n",
    "    train_df = pd.read_csv(user_data_dir_train, sep = '\\t') # Change seperator if needed\n",
    "    pred_df = pd.read_csv(user_data_dir_pred, sep = '\\t') # Change seperator if needed\n",
    "    print ('User datasets found and loaded')\n",
    "else:\n",
    "    train_df = pd.read_csv(synth_data_dir_train, sep = '\\t')\n",
    "    pred_df = pd.read_csv(synth_data_dir_pred, sep = '\\t')\n",
    "    print ('Pre-uploaded synthetic datasets found and loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd8ffb85-24b6-4c3f-946a-c2350e2b4b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data cleaning: drop rows that are duplicate and change any NA values to the average value of the column it's in. \n",
    "train_cleaned = basic_cleaning (train_df)\n",
    "pred_cleaned = basic_cleaning (pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d8ba0d5-7254-419d-be28-b7ebcf7d9339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function that changes categorical data into numerical data so it can be used as input for the models \n",
    "train_processed, pred_processed = convert_categorical_to_dummies (train_cleaned, pred_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa7d1dbe-2ffa-48a0-9557-852e7b4768a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function standardize_min_max to standardize the train and pred datasets using a min max scaler and save them as .csv files in the folder data/interim \n",
    "# These datasets can be used for the lasso regression model, because reggression is sensitive to scaling \n",
    "train_df_sdd, pred_df_sdd = standardize_dataset (train_processed, pred_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23413d87-8933-4102-a422-067e6d96717a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models on the data...\n",
      "Fitting 5 folds for each of 486 candidates, totalling 2430 fits\n",
      "Fitting 5 folds for each of 199 candidates, totalling 995 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    }
   ],
   "source": [
    "# Code checks if retrain_models = True or False in config.py file. If using your own datasets, change retrain_models in the config.py file to True, so the models are trained on your own data. \n",
    "# Warning: training the models can take a long time depending on the size and contents of your data\n",
    "if retrain_models == True:\n",
    "    print ('Training models on the data...')\n",
    "    best_rf_model = randomforestregressormodel_train(train_processed)\n",
    "    best_lasso_model = lassoregressionmodel_train(train_df_sdd)\n",
    "    best_svm_model = supportvectormachinemodel_train(train_df_sdd)\n",
    "else:\n",
    "    print('retrain_models is False in the config.py file, laoding the the pre-trained models')\n",
    "    \n",
    "# Folds = number of train/test splits of the dataset, candidates = models with different parameters and fits = folds * candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "150e4238-74a0-4991-8a44-6f2126323cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import code that loads the trained models and that can predict on the dataset\n",
    "from module.modeling.predict import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a2e71d9-630a-48d4-b5e7-28dd5c22512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the loaded models to predict on the datasets. The lasso model uses the standardized dataset ot predict an, but takes the student numnbers from the \n",
    "# regular predict dataset. \n",
    "ranked_students_rf = randomforestregressormodel_pred (pred_processed)\n",
    "ranked_students_lasso = lassoregressionmodel_pred(pred_df_sdd, pred_processed)\n",
    "ranked_students_svm = supportvectormachinemodel_pred(pred_df_sdd, pred_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00e0878c-5341-4c5d-beb6-bd0880cd1142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file saved as .xlsx\n"
     ]
    }
   ],
   "source": [
    "if save_method == 'xlsx':\n",
    "    # Save results as excel file in the folder predictions. Predictions is in the models folder.\n",
    "    writer = pd.ExcelWriter('models/predictions/ranked_students.xlsx', engine='xlsxwriter')\n",
    "    ranked_students_rf.to_excel(writer, sheet_name='Random Forest', startrow=0, startcol=0, index=False)\n",
    "    ranked_students_lasso.to_excel(writer, sheet_name='Lasso', startrow=0, startcol=0, index=False)\n",
    "    ranked_students_svm.to_excel(writer, sheet_name='Support Vector Machine', startrow=0, startcol=0, index=False)\n",
    "    writer.close()\n",
    "    print ('Output file saved as .xlsx in the /models/predictions folder')\n",
    "elif save_method == 'csv':\n",
    "    # Save results as CSV files\n",
    "    ranked_students_rf.to_csv('models/predictions/csv_output/ranked_students_rf.csv', sep='\\t', index=False)\n",
    "    ranked_students_lasso.to_csv('models/predictions/csv_output/ranked_students_lasso.csv', sep='\\t', index=False)\n",
    "    ranked_students_svm.to_csv('models/predictions/csv_output/ranked_students_svm.csv', sep='\\t', index=False)\n",
    "    print ('Output file saved as .csv in the /models/predictions/csv_output folder'')\n",
    "else:\n",
    "    print('Invalid save method. Please choose \"xlsx\" or \"csv\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00097337-44f8-406f-9aee-6ef1e07e8030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba1d900-2eef-4bdc-8128-f06b3f748cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa7a6f7-da89-47ba-934e-112bd87bdb84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
